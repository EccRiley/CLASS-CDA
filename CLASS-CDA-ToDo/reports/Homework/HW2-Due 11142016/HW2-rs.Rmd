---
title: "HW-2 R Notebook"
author: "Rachel M. Smith"
date: "`r format(Sys.Date(), '%d %B %Y')`"
---

-----

```{r setup, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache=FALSE}
source("../SETUP.R")
knitr::opts_chunk$set(
    tidy = FALSE,
    echo = FALSE,
    cache = FALSE,
    fig.keep = 'high',
    fig.show = 'hold',
    results = 'hide',
    autodep = T,
    Rplot = TRUE,
    dev = 'pdf',
    fig.path = 'graphics/HW2/rplot-q1-',
    fig.width = 7,
    fig.height = 7,
    out.width = "\\linewidth"
    )
```

# Question 1


```{r dat, results = 'asis'}
dat <- R.rspss("data/race2.sav") 
## My "R.rspss()" function is a convenience wrapper function for 
    ## "read.spss()" {pkg:foreign} with the default values for 
    ## "use.value.labels" & "to.data.frame" set to "FALSE" and "TRUE", 
    ## respectively. ## 

dat <- R.rspss("data/race2.sav") 
## My "R.rspss()" function is a convenience wrapper function for 
    ## "read.spss()" {pkg:foreign} with the default values for 
    ## "use.value.labels" & "to.data.frame" set to "FALSE" and "TRUE", 
    ## respectively. ## 

dat <- within(dat, {## I like to keep the a numeric and factor copy 
                        ## of variables. Below, I'm defining the factor
                        ## variables for "ped" and "offense" according to 
                        ## their original labels in the spss datafile. ##
    offense <- sapply(offense, R.na, v = 0)
    ped.f <- factor(ped, 
                    levels = unique(ped), 
                    labels = c("African American", 
                               "Asian", 
                               "Hispanic", 
                               "Native American", 
                               "White"))
    offense.f <- factor(offense, 
                        levels = c(1, 2), 
                        labels = c("major", 
                                   "minor"))
})

s.dat <- R.msmm(dat)
## My "R.msmm()" function is another convenience function I wrote, which 
    ## calculates the mean, standard deviation, minimum, and maximum
    ## (hence "msmm") values and a count of existing NAs for each 
    ## numeric or integer column in a given dataframe and returns a summative 
    ## dataframe of these values. ##

s.dat

ped.t <- table(dat$ped.f) %>% as.data.frame() 
## dataframe of factor level counts for the "ped.f" factor variable ##
offense.t <- table(dat$offense.f) %>% as.data.frame()
## dataframe of factor level counts for the "offense.f" factor variable ##

kable(ped.t, col.names = c("Pedestrian Race", "Frequency"))
kable(offense.t, col.names = c("Offense", "Frequency"))

dat.ft <- ftable(dat$ped, dat$offense) %>% 
    as.matrix()
## The "ftable()" function {pkg:base} produces a flat contingency table, and 
    ## is thus highly convenient for extracting joint frequencies ##
dimnames(dat.ft) <- list("Pedestrian Race" = paste(levels(dat$ped.f)), 
                         "Offense" = c("NA", 
                                     paste(levels(dat$offense.f)))
                         )
dat.ft
    ## Shows that the NAs (i.e., '0's) in dat$offense are for 
        ## Asian, Hispanic, and Native American; but not 
        ## White nor African American, cases. ##
    ## This means that we can just remove all cases (rows) with NAs, 
        ## since we are only interested in the White and African American 
        ## cases for this analysis. ##

dat <- na.omit(dat) %>% 
    droplevels() 
## ^- remove cases with "NAs" throughout the dataframe, then 
    ## drop the any resultingly unused levels of the factor variables ##
```

```{r mA, results='asis'}
m.A <- matrix(c("$n_{11}$", "$n_{12}$", "**$n_{1+}$**",
                "$n_{21}$", "$n_{22}$", "**$n_{2+}$**",
                "**$n_{+1}$**", "**$n_{+2}$**", "_**$n_{++}$**_"), nrow = 3, byrow = TRUE)
dimnames(m.A) <- list("_**I**_" = c("$i_{1}$", "$i_{2}$", "$\\pi_{i+}$"),
                      "_**J**_" = c("$j_{1}$", "$j_{2}$", "$\\pi_{+j}$"))
# kable(m.A, caption = "Data Structure")
```

```{r ft}
# str(ft.m)
ft <- ftable(dat$ped.f, dat$offense.f) %>% 
    as.matrix()
dimnames(ft) <- list(ped = dimnames(ft)[[1]], 
                     offense = dimnames(ft)[[2]])
n <- sum(ft)
pi.j <- apply(ft, 1, sum) %>% matrix()
rownames(pi.j) <- rownames(ft)
pi.i <- apply(ft, 2, sum) %>% matrix(nrow = 1, ncol = 2)
colnames(pi.i) <- colnames(ft)
pi.i <- cbind(pi.i, n)

ft.j <- cbind(ft, pi.j)

ft.m <- rbind(ft.j, pi.i)

pT <- ft.m[[9]]

AA <- ft.m[[7]]
pAA <- paste0(round((AA/pT)*100, digits = 2), "%")
WH <- ft.m[[8]]
pWH <- paste0(round((WH/pT)*100, digits = 2), "%")

MA <- ft.m[[4]]
pMA <- paste0(round((MA/pT)*100, digits = 2), "%")
MI <- ft.m[[6]]
pMI <- paste0(round((MI/pT)*100, digits = 2), "%")

AAMA <- ft.m[[1]]
pAAMA <- paste0(round((AAMA/pT)*100, digits = 2), "%")
WHMA <- ft.m[[2]]
pWHMA <- paste0(round((WHMA/pT)*100, digits = 2), "%")
AAMI <- ft.m[[3]]
pAAMI <- paste0(round((AAMI/pT)*100, digits = 2), "%")
WHMI <- ft.m[[5]]
pWHMI <- paste0(round((WHMI/pT)*100, digits = 2), "%")

```

```{r ftkab, results='asis'}
ft.mm <- ft.m
dimnames(ft.mm) <- list(Race = c("_African American_", 
                                 "_White_", 
                                 "$\\pi_{i+}$"), 
                       Offense = c("_Major_", 
                                   "_Minor_", 
                                   "$\\pi_{+j}$"))
ft.mm <- matrix(ft.mm, nrow = 3, byrow = T, 
                dimnames = list(Race = c("**African American**", 
                                         "**White**", 
                                         "**$\\pi_{i+}$**"), 
                                Offense = c("Major", 
                                            "Minor", 
                                            "$\\pi_{+j}$")))

kable(ft.mm, caption = "Contingency Table of Pedestrians Stopped by Portland Police: Pedestrian Race (2 Levels) x Severity of Offense (2 Levels).")
```

```{r tbl, fig.margin=TRUE, results='asis'}
tbl <- with(dat, {
    table(ped.f, offense.f)
})
dimnames(tbl) <- list(ped.f = levels(dat$ped.f),
                      offense.f = levels(dat$offense.f))
# par(family = "serif")
# mosaicplot(tbl, type = "pearson", color = pal_my.a75[c(5, 16)], 
           # main = "Cross-Tabulation of Pedestrian Race X Offense",
           # xlab = "Pedestrian Race", ylab = "Offense Severity", cex = 1)
```
 
## $1.a.$ Loglinear Model

$$ \log(\mu_{ij}) = \lambda + \lambda_{i}^{X} + \lambda_{j}^{Y} + \lambda_{ij}^{XY} $$

`r tufte::newthought("Loglinear Analysis Summary.")` A loglinear model was used to test the association between pedestrian race and whether individuals were stopped by Portland Police (_PPB_) for major versus minor offenses. `r pWH` of pedestrians stopped by PPB were White, and `r pAA` were African American ($N_{Total} = `r pT`$). Among the `r AA` African American pedestrians, `r pAAMA` (`r AAMA`) were stopped for major offenses, while `r pAAMI` (`r AAMI`) were stopped for minor offenses. Among the `r WH` White pedestrians, `r pWHMA` (`r WHMA`) were stopped for major offenses, while `r pWHMI` (`r WHMI`) were stopped for minor offenses. Results from the likelihood ratio test of the $2 x 2$ contingency table (see above) indicated no significant differences regarding these factors, $G^{2}(1) = 0.14, p = 0.70$.

-----

```{r results='asis'}
library(MASS) ## "loglm()" (... and many other useful functions) ##
llm <- loglm( ~ ped.f + offense.f, 
              data = tbl)
llm
# str(llm)
# llm.df <- data.frame(chsq = c(llm$lrt, llm$pearson), df = llm$df)
# llm.df
```


\newpage

## $1.b.$ Logistic Regression Model

$$ \ln\left(\frac{\pi}{1 - \pi}\right) = \alpha + \beta X $$

$$ \pi = \frac{e^{\alpha + \beta X}}{1 + e^{\alpha + \beta X}} $$


```{r lrm}
lrm <- glm(offense.f ~ ped, data = dat, family = "binomial", x = TRUE)
summary(lrm)
lrm.b <- coef(lrm)
lrm.b1 <- coef(lrm)[[2]] ## \beta_{1} (i.e., "ped") ##
lrm.b0 <- coef(lrm)[[1]] ## \beta_{0} (i.e., the model intercept) ##

x <- summary(lrm)

#######
## Writing a function for restructuring output from 
    ## "summary.glm()" as a dataframe ##
######
R.glmdf <- function(x){ ## "x" must be an object of class "summary.glm"...
                            ## ... currently only works for simple logistic
                            ## regression (i.e., only one predictor) ##
    se.cmpn <- x[c("dispersion", "cov.unscaled")]
        ## ^- "cmpn" = "components" abbreviated ##
        ## see "`r names(summary(<SOME GLM OBJECT>))`" ##
    se.a <- se.cmpn[[1]]
    se.b <- se.cmpn[[2]]
    se.ab <- se.a*se.b ## "covmat" ##
    se.c <- diag(se.ab) ## "var.cf" ##
    se.x <- sqrt(se.c) ## "s.err" ##
    z.a <- c(x$coefficients[[1]], x$coefficients[[2]])
    z.x <- z.a / se.x
    p.x <- 2 * pnorm(-abs(z.x))
    x.df <- data.frame(Estimate = c(x$coefficients[[1]],
                                    x$coefficients[[2]]),
                       SE = se.x,
                       Z = z.x,
                       p.value = p.x)
    return(x.df)
}


x.summ <- R.glmdf(x)
```

```{r lrmFits}
## **Null Deviance** ##
nulldev <- lrm$null.deviance
nulldev.df <- lrm$df.null
nulldev.p <- c(round(nulldev, 2), nulldev.df)

## **Residual Deviance** ##
dev <- lrm$deviance
dev.df <- lrm$df.residual
dev.p <- c(round(dev, 2), dev.df)

## **AIC** ##
aic <- lrm$aic
aic.p <- c(round(aic, 2), " ")

fits <- as.data.frame(rbind(nulldev.p, dev.p))
rownames(fits) <- c("**Null Deviance**", "**Residual Deviance**")
names(fits) <- c("Estimate", "Degrees of Freedom")

```

```{r lrmORCI}

CI.b <- confint(lrm, trace = FALSE)

OR <- exp(coef(lrm)) 
CI <- confint(lrm)

CIb <- cbind(coef(lrm), CI.b)
CIb.labs <- c("**$\\beta$**", dimnames(confint(lrm))[[2]])
CIb <- rbind(CIb.labs, round(CIb, 4))
dimnames(CIb)[[1]][1] <- " "
dimnames(CIb)[[2]] <- c(" ", "$CI_{\\beta}$", " ")

## odds ratios and 95% CI ##
ORCI <- exp(cbind(coef(lrm), CI))
ORCI.labs <- c("**$\\Phi$**", dimnames(confint(lrm))[[2]])
ORCI <- rbind(ORCI.labs, round(ORCI, 4))
dimnames(ORCI)[[1]][1] <- " "
dimnames(ORCI)[[2]] <- c(" ", "$CI_{\\Phi}$", " ")

## Wald's Chi-Square ## 
library(aod) ## "wald.test()" ##
chsq <- wald.test(b = coef(lrm), Sigma = vcov(lrm), Terms = 2)
chsq.v <- chsq$result
chsq.v <- chsq.v$chi2[[1]]

library(lmtest) ## "lrtest()" ##
lrchsq <- lrtest(lrm)[2, -3]
lrchsq <- lrchsq[, c(2, 1, 3, 4)]
names(lrchsq) <- c("Log Likelihood", "_df_", "$\\chi^{2}$", "_p_")

library(modEvA)
rsq <- RsqGLM(model = lrm) %>% sapply(round, 4)
pander(rsq)
rsq.perc <- (rsq[2]*100)
```

`r tufte::newthought("Logistic Regression Analysis Summary.")` A logistic regression analysis was conducted to test whether pedestrian race^[_African American_ or _White_] predicted whether individuals were stopped by Portland Police for _major_, versus _minor_, offenses. Results for the model indicated that the severity of offenses was not predicted according to the two levels of pedestrians' race, likelihood ratio $\chi^{2}(1) = `r lrchsq[1, 3]`$ (n.s.)<!--, $\\textit{b} = `r round(lrm.b1, 3)`$ (n.s.)-->. The _Nagelkerke pseudo_-$R^{2}$ indicated that $< 1\%$ of the variance in offense severity was accounted for by the race of pedestrians stopped by PPB^[_pseudo_-$R_{2} = `r paste0(rsq[[2]]*100, "\\%")`$]. The model estimates and fit indices are summarized below.

-----


```{r results = 'asis'}
# chsq
kable(lrchsq, row.names = FALSE, caption = "Likelihood Ratio $\\chi^{2}$")
```


```{r results='asis'}
kable(x.summ, caption = "Logistic Regression Model Summary")#, col.names = c("Estimate (_$\\hat{b}$_)", "_SE_", "Wald's "))
```

```{r results='asis'}
kable(CIb, align = rep('r', ncol(CIb)), 
      caption = "Logistic Regression Coefficients ($\\beta$) \\& 
      Coresponding Confidence Intervals (_CI_)")

kable(ORCI, align = rep('r', ncol(ORCI)), 
      caption = "Logistic Regression Odds Ratios ($\\Phi$) \\& 
      Coresponding Confidence Intervals (_CI_) [note]") %>%
    add_footnote("Confidence intervals are based on the logistic regression 
                 model's profiled log-likelihood function, 
                 rather than the standard errors", 
                 threeparttable = TRUE)
```

```{r lrmresults4, results='asis'}
kable(fits, caption = "Logistic Regression Model Fit Statistics")
```


\newpage
## $1.c.$ Findings Comparisons

Findings for the loglinear and logistic regression models above support findings from the $\chi^{2}$ analysis conducted previously (_HW-1_). In particular the likelihood ratio $\chi^{2}$ found in _Homework-1, Question 3.c._ is exactly the same as that found from testing the loglinear model in _Question 1.a_ here ($\chi^{2} = 0.1437, p = 0.70$).


-----

`r tufte::newthought("Original")` Contingency Table \& Group Comparisons via Pearson $\chi^{2}$.


```{r hw1q3c, fig.asp=1, results='asis'}
dat2 <- read.spss("data/race2.sav", to.data.frame = TRUE)
dat2 <- droplevels(na.omit(dat2))

tbl <- ftable(dat2$ped, dat2$offense)
tbl.df <- as.data.frame(tbl)
names(tbl.df) <- c("Race", "Offense", "Freq")

xtbl <- xtabs(Freq ~ Offense + Race, data = tbl.df, 
              sparse = TRUE, subset = NULL, na.action = NULL)
xtbl.m <- as.matrix(xtbl)
xsq <- chisq.test(xtbl.m)

library(descr) ## "CrossTable()" ##

ctab <- CrossTable(tbl.df$Race, tbl.df$Offense,
                   digits = list(expected = 3, prop = 3, percent = 3, others = 3),
                   expected = F,
                   prop.r = F, prop.c = F, prop.t = F, prop.chisq = F, 
                   chisq = T, fisher = F, mcnemar = F,
                   dnn = c("Race", "Frequency of Stops"), cell.layout = F,
                   row.labels = T,
                   total.r = T, total.c = T,
                   xlab = expression(italic("Frequency of Stops")),
                   ylab = expression(italic("Race")))

library(vcd) ## "assocstats()" ##
assocstats(tbl)
```

\newpage
# Question-2

`r margin_note("\\textit{Q-2 Data:} \\texttt{'child.sav'} \\& \\texttt{'child2.sav'}")`

```{r q2Dat}
library(foreign) ## "read.spss()" ##
dat <- read.spss("data/child.sav", to.data.frame = TRUE)
dat <- na.omit(dat)
```

# $2.a.$ Three-Way Loglinear Model

```{r fig.margin=TRUE}
library(MASS)
tbl <- with(dat, {
    table(abuse, boyfriend, program)
})
dimnames(tbl) <- list(Abuse = c("no", "yes"),
                      Boyfriend = c("no", "yes"),
                      Program = c("no", "yes")
                      )
noquote(tbl)

par(family = 'serif')
mosaicplot(~ Abuse + Boyfriend + Program, data = tbl, color = TRUE, main = "Abuse x Boyfriend x Program", type = 'deviance')
```

$$ \log(\mu_{ijk}) = \lambda + \lambda_{i}^{X} + \lambda_{j}^{Y} + \lambda_{k}^{z} + \lambda_{ij}^{XY} + \lambda_{ik}^{XZ} + \lambda_{jk}^{YZ} + \lambda_{ijk}^{XYZ} $$

-----

```{r}
library(MASS) ## "loglm()" (... and many other useful functions) ##
llm <- loglm(~ Abuse, 
             digits = 4, 
             data = tbl)
# llm
llm1 <- loglm(~ Abuse + 
                  Boyfriend, 
              digits = 4, 
              data = tbl)
# llm1
llm2 <- loglm(~ Abuse + 
                  Boyfriend + 
                  Program, 
              digits = 4, 
              data = tbl)
# llm2
llm3 <- loglm(~ Abuse:Boyfriend + 
                  Abuse:Program + 
                  Boyfriend:Program, 
              digits = 4, 
              data = tbl)
# llm3

# anova(llm, llm1, llm2, llm3)
# mosaic(llm3, gp=shading_Friendly)
# llm.s <- step(llm4)
```

`r tufte::newthought("Three-Way Loglinear Analysis Summary.")` A three-way loglinear model was conducted examing the three-way contingency table (abuse-x-boyfriend-program) to investigate whether program participation impacted the association between the boyfriend variable and any report of abuse (joint frequencies are provided in table below). Results from the likelihood ratio test (see below) indicated no significant differences regarding these factors, $G^{2}(1) = 3.318, p = 0.07$.

-----

```{r llm, results='asis'}
llm3
```

\newpage
## $2.b.$ Logistic Regression with an Interaction Term

$$ \ln\left(\frac{\pi}{1 - \pi}\right) = \alpha + \beta X $$

$$ \pi = \frac{e^{\alpha + \beta X}}{1 + e^{\alpha + \beta X}} $$


```{r echo=TRUE, results='asis'}
lgm <- glm(abuse ~ boyfriend + program + boyfriend*program, data = dat, family = "binomial") 
```

`r tufte::newthought("Multiple Logistic Regression Analysis Summary.")` A multiple logistic regression analysis was conducted predicting abuse by program participation, whether the mother had a boyfriend, and the program-x-boyfriend interaction. The interaction was only marginally significant, $\beta = 1.461, SE = 0.8615, p = 0.09$. The model's results are summarized below.

```{r echo=FALSE, results='asis'}
lgm
## "interaction.plot()" from the {stats} package ##
with(dat, {
    interaction.plot(
    abuse,
    program,
    boyfriend,
    col = c("darkgray", "#cd0000"),
    lwd = 2,
    main = "Interaction Effects",
    ylab = expression(mu[welfare]),
    xlab = "Abuse",
    trace.label = "Program"
    )
})
anova(lgm)
```

\newpage
## $2.c$ Findings Comparison

Results from the original analysis (HW-1) showed a $\chi^{2}$ statistic similar to that found in the loglinear analysis ($Q2.a.$) here ($\chi^{2}_{1} = 4, \chi^{2}_{2} = 3.3$). However, the signifance found in the original analysis was not replicated in the analysis conducted here, such that the association between the boyfriend variable and abuse, as tested in the analyses above, is not contingent upon the program participation condition.


\newpage
## $2.d$% Multiple Logistic Regression

```{r resetup, echo=FALSE, results='hide'}
rm(list = ls()) ## reset workspace for new dataset ##
source("../SETUP.R") ## still need all of my setup tools though ##
```

`r tufte::newthought("Data Summary")`

```{r q2dat2, results = 'asis'}
dat2 <- R.rspss("data/child2.sav", vlabs = TRUE) ## factored variables ##
    ## (see my "SETUP.R" file for the 'R.rspss()' function definition) ##
dat2.n <- R.rspss("data/child2.sav", vlabs = FALSE) ## numeric variables ##
dat2 <- na.omit(dat2)
dat2.n <- na.omit(dat2.n)

# R.msmm(dat2.n) ## numeric data summary ##
sapply(dat2[, -4], table) ## summary of factored variables ##
```


-----

`r tufte::newthought("Multiple Logistic Regression Analysis Summary.")` A multiple logistic regression analysis was conducted predicting abuse by program participation, whether the mother had a boyfriend, the mother's race, and the frequency of welfare encounters. All predictors in the model except for the program participation term were significant. The model estimates and fit indices are summarized below.

```{r lgm, fig.margin=TRUE, results='asis'}
lgm <- glm(abuse ~ program + boyfriend + white + welfare, 
           data = dat2.n, 
           family = binomial(link = "logit")) 
lgm
anova(lgm, test = "LRT")

library(popbio)
logi.hist.plot(dat2.n$welfare, dat2.n$abuse, boxp=FALSE, type="hist", col="gray")
```


```{r}
## **Null Deviance** ##
nulldev <- lgm$null.deviance
nulldev.df <- lgm$df.null
nulldev.p <- c(round(nulldev, 2), nulldev.df)

## **Residual Deviance** ##
dev <- lgm$deviance
dev.df <- lgm$df.residual
dev.p <- c(round(dev, 2), dev.df)

## **AIC** ##
aic <- lgm$aic
aic.p <- c(round(aic, 2), " ")

fits <- as.data.frame(rbind(nulldev.p, dev.p, aic.p))
rownames(fits) <- c("**Null Deviance**", "**Residual Deviance**", "**AIC**")
names(fits) <- c("Estimate", "Degrees of Freedom")

CI.b <- confint(lgm, trace = FALSE)

OR <- exp(coef(lgm)) 
CI <- confint(lgm)

CIb <- cbind(coef(lgm), CI.b)
CIb.labs <- c("**$\\beta$**", dimnames(confint(lgm))[[2]])
CIb <- rbind(CIb.labs, round(CIb, 4))
dimnames(CIb)[[1]][1] <- " "
dimnames(CIb)[[2]] <- c(" ", "$CI_{\\beta}$", " ")

## odds ratios and 95% CI ##
ORCI <- exp(cbind(coef(lgm), CI))
ORCI.labs <- c("**$\\Phi$**", dimnames(confint(lgm))[[2]])
ORCI <- rbind(ORCI.labs, round(ORCI, 4))
dimnames(ORCI)[[1]][1] <- " "
dimnames(ORCI)[[2]] <- c(" ", "$CI_{\\Phi}$", " ")


library(lmtest) ## "lrtest()" ##
lrchsq <- lrtest(lgm)[2, -3]
lrchsq <- lrchsq[, c(2, 1, 3, 4)]
names(lrchsq) <- c("Log Likelihood", "_df_", "$\\chi^{2}$", "_p_")

library(modEvA)
rsq <- RsqGLM(model = lgm) %>% sapply(round, 4)
pander(rsq)
rsq.perc <- (rsq[2]*100)
kable(lrchsq, row.names = FALSE, caption = "Likelihood Ratio $\\chi^{2}$")
```

`r tufte::newthought("Confidence Intervals (CI) \\& Odds Ratios (OR)")`

```{r lrmresults2, results='asis'}
kable(CIb, align = rep('r', ncol(CIb)), 
      caption = "Logistic Regression Coefficients ($\\beta$) \\& 
      Coresponding Confidence Intervals (_CI_)")

kable(ORCI, align = rep('r', ncol(ORCI)), 
      caption = "Logistic Regression Odds Ratios ($\\Phi$) \\& 
      Coresponding Confidence Intervals (_CI_) [note]") %>%
    add_footnote("Confidence intervals are based on the logistic regression 
                 model's profiled log-likelihood function, 
                 rather than the standard errors", 
                 threeparttable = TRUE)
```

```{r lrmresults3, results='asis'}
kable(fits, caption = "Logistic Regression Model Fit Statistics")
```


\newpage
## $2.e.$ Moderation Analysis


`r tufte::newthought("Mediation Analysis Summary.")` A regression model was tested to investigate whether participation in the Early Head Start program moderated the assocation between the number of welfare encounters and the probability of abuse, with the mother's race included in the model as a covariate. Except for the program participation term, all model coefficients were significant, including the welfare-x-program interaction term (see Table 13 below).

```{r results='asis', fig.margin=TRUE}
dat2.c <- within(dat2.n, {## could also do this with an "apply()" function ##
    boyfriend <- boyfriend - mean(boyfriend)
    program <- program - mean(program) 
    welfare <- welfare - mean(welfare)
    white <- white - mean(white)
})

dat2.c$int <- dat2.c$program * dat2.c$boyfriend

library(mediation) ## "mediations()" & "plot.mediations()" ##

set.seed(42) ## i'll explain later ##
treatment <- c("welfare")
mediators <- c("program")
outcome <- c("abuse")
covariates <- c("white")
datasets <- list(dat2.c = dat2.c)
m.model <- mediations(datasets, treatment, mediators, outcome, covariates,
                      families = c("gaussian", "binomial"), 
                      interaction = TRUE,
                      conf.level = .95, sims = 50)

mod.y <- m.model$abuse.welfare.program[["model.y"]]
mod.m <- m.model$abuse.welfare.program[["model.m"]]

mod.y
mod.m

plot(m.model, labels = c("Indirect", "Direct", "Total"))

# 
# mod.diref0 <- m.model$abuse.welfare.program[["z0"]]
# mod.diref1 <- m.model$abuse.welfare.program[["z1"]]
# mod.medef0 <- m.model$abuse.welfare.program[["d0"]]
# mod.medef1 <- m.model$abuse.welfare.program[["d1"]]
# x <- data.frame(dir = c(mod.diref0, mod.diref1), med = c(mod.medef0, mod.medef1))
```


```{r intEffects, echo=TRUE, results='asis'}
## "interaction.plot()" from the {stats} package ##
with(dat2, {
    interaction.plot(
    abuse,
    program,
    welfare,
    col = c("darkgray", "#cd0000"),
    lwd = 2,
    main = "Interaction Effects",
    ylab = expression(mu[welfare]),
    xlab = "Abuse",
    trace.label = "Program"
    )
})
```

\newpage
# Question-3


The data for the remaing sets of analyses are from a national telephone interview study of batterer intervention program (BIP) standards advisory and compliance monitoring committees. Respondents were asked a series of questions varying in structure from _open-ended_ to simple _yes-or-no_. These analyses will concern the discrete data collected in response to the following interview questions:

> **Q3:** How many members currently serve on your standards committee?
> **Q7:** Does your organization have methods for assessing programsâ€™ feedback about the standards?
> **Q8:** Do the standards apply to programs designed for all genders?

The primary interest for the below analyses relate to an overarching effort to implement and sustain effective and appropriate anti-violence intervention strategies among female-identified perpetrators of same-sex violence. The above listed questions provide a mix of continuous numeric and dichotomous (`0 = No`; `1 = Yes`) indicators of responding states' current organizational and ideological capacities for such intervention strategies. 

-----

`r tufte::newthought("Multiple Logistic Regression Analysis Summary.")` A multiple logistic regression analysis was conducted predicting whether states' batterer intervention program (BIP) standards were gender inclusive (_Q8_) by the size of state standards' committees (_Q3_), whether proccesses were in place for assessing BIPs' feedback about the standards (_Q7_), and the interaction of these two predictors (_Q3-x-Q7_). None of these predictors were significant. The model estimates and fit indices are summarized below.


```{r q3Dat}
dat <- read.csv("data/states_new.csv")
# datmap <- read.csv("data/usmap.csv")

dat <- dat[, c("Q3", "Q7", "Q8")]
dat <- na.omit(dat)
```

```{r}
dat <- subset(dat, Q7 < 2)
dat <- subset(dat, Q8 < 2)
dat.f <- within(dat, {## could also do this with an "apply()" function ##
    Assessments <- factor(Q7, levels = c(0, 1), labels = c("No", "Yes"))
    Gender.Inclusive <- factor(Q8, levels = c(0, 1), labels = c("No", "Yes"))
})

dat.c <- within(dat, {## could also do this with an "apply()" function ##
    Q7 <- Q7 - mean(Q7)
    Q3 <- Q3 - mean(Q3)
})

lgm <- glm(Q8 ~ Q3 + Q7 + Q3*Q7, 
           data = dat.c, 
           family = binomial(link = "logit")) 
lgm.b <- coef(lgm)
lgm.b1 <- coef(lgm)[[2]] ## \beta_{1} (i.e., "ped") ##
lgm.b0 <- coef(lgm)[[1]] ## \beta_{0} (i.e., the model intercept) ##

x <- summary(lgm)

#######
## Writing a function for restructuring output from 
    ## "summary.glm()" as a dataframe ##
######
R.glmdf <- function(x){ ## "x" must be an object of class "summary.glm"...
                            ## ... currently only works for simple logistic
                            ## regression (i.e., only one predictor) ##
    se.cmpn <- x[c("dispersion", "cov.unscaled")]
        ## ^- "cmpn" = "components" abbreviated ##
        ## see "`r names(summary(<SOME GLM OBJECT>))`" ##
    se.a <- se.cmpn[[1]]
    se.b <- se.cmpn[[2]]
    se.ab <- se.a*se.b ## "covmat" ##
    se.c <- diag(se.ab) ## "var.cf" ##
    se.x <- sqrt(se.c) ## "s.err" ##
    z.a <- c(x$coefficients[[1]], x$coefficients[[2]])
    z.x <- z.a / se.x
    p.x <- 2 * pnorm(-abs(z.x))
    x.df <- data.frame(Estimate = c(x$coefficients[[1]],
                                    x$coefficients[[2]]),
                       SE = se.x,
                       Z = z.x,
                       p.value = p.x)
    return(x.df)
}


## **Null Deviance** ##
nulldev <- lgm$null.deviance
nulldev.df <- lgm$df.null
nulldev.p <- c(round(nulldev, 2), nulldev.df)

## **Residual Deviance** ##
dev <- lgm$deviance
dev.df <- lgm$df.residual
dev.p <- c(round(dev, 2), dev.df)

## **AIC** ##
aic <- lgm$aic
aic.p <- c(round(aic, 2), " ")

fits <- as.data.frame(rbind(nulldev.p, dev.p))
rownames(fits) <- c("**Null Deviance**", "**Residual Deviance**")
names(fits) <- c("Estimate", "Degrees of Freedom")

OR <- exp(coef(lgm)) 

library(lmtest) ## "lrtest()" ##
lrchsq <- lrtest(lgm)[2, -3]
lrchsq <- lrchsq[, c(2, 1, 3, 4)]
names(lrchsq) <- c("Log Likelihood", "_df_", "$\\chi^{2}$", "_p_")

library(modEvA)
rsq <- RsqGLM(model = lgm) %>% sapply(round, 4)
pander(rsq)
rsq.perc <- (rsq[2]*100)
```

```{r results='asis'}
lgm
anova(lgm, test = "LRT")
library(popbio)
logi.hist.plot(dat2.n$welfare, dat2.n$abuse, boxp=FALSE, type = "hist", col = "gray")

kable(lrchsq, row.names = FALSE, caption = "Likelihood Ratio $\\chi^{2}$")
# kable(OR, align = rep('r', ncol(CIb)), 
      # caption = "Logistic Regression Coefficients ($\\beta$) \\& 
      # Coresponding Confidence Intervals (_CI_)")
kable(fits, caption = "Logistic Regression Model Fit Statistics")
```
